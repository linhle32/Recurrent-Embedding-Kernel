{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Embedding Kernel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda0: GeForce GTX 1080 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=cuda0,floatX=float32,exception_verbosity='high'\"\n",
    "\n",
    "from theano import *\n",
    "import theano.tensor as T\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial import distance_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "tsx = pd.read_csv('SPY.csv')\n",
    "\n",
    "#get differenced features\n",
    "X = tsx.values[:,1:-2]\n",
    "Xd = np.diff(X,axis=0)\n",
    "#normalize features\n",
    "Xsd = ((Xd - np.mean(Xd,axis=0)) / np.std(Xd.astype(np.float32),axis=0)).astype(np.float32)[:-1][-5365:]\n",
    "\n",
    "#get up/down labels\n",
    "yt = tsx['Adj Close'].values.astype(np.float32)\n",
    "Y = (np.diff(yt)[1:] > 0) * 1\n",
    "Y = Y[-5365:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building REK computational flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiddens must have three lists: \n",
    "#   recurrent layer sizes, \n",
    "#   embedding layer sizes, \n",
    "#   and kernel layer sizes\n",
    "hiddens = [[36,36,36],[36,36],[36,36]]\n",
    "\n",
    "#activation function\n",
    "activation = T.nnet.relu\n",
    "#input shape\n",
    "n_in = Xsd.shape[1]\n",
    "\n",
    "\n",
    "###REDK flow\n",
    "seed = 132345\n",
    "rng = np.random.RandomState(seed)\n",
    "x = T.matrix('x')\n",
    "y = T.imatrix('y')\n",
    "#function to generate weights\n",
    "def genW(size):\n",
    "    return np.asarray(\n",
    "        rng.uniform(\n",
    "            low=-0.1,\n",
    "            high=0.1,\n",
    "            size = size\n",
    "        ),\n",
    "        dtype = theano.config.floatX)\n",
    "#get architectures of recurrent, embedding, and kernel blocks\n",
    "rl,el,kl = hiddens\n",
    "nr = len(rl)\n",
    "nl = len(el)\n",
    "nh = len(kl)\n",
    "M = n_in\n",
    "N = rl[-1]\n",
    "nr = len(rl)\n",
    "\n",
    "######\n",
    "#Recurrent block\n",
    "W0 = theano.shared(value=genW((M,rl[0])),name=\"W0\",borrow=True)\n",
    "Wu = theano.shared(value=genW((rl[-1],rl[0])),name=\"Wu\",borrow=True)\n",
    "b0 = theano.shared(value=np.zeros(rl[0],dtype=theano.config.floatX),name=\"b0\",borrow=True)\n",
    "u0 = theano.shared(value=np.zeros((1,N),dtype=theano.config.floatX),borrow=True)\n",
    "params = [W0,Wu,b0]\n",
    "W = []\n",
    "b = []\n",
    "for i in range(0,nr-1):\n",
    "    W.append(\n",
    "        theano.shared(value=genW((rl[i],rl[i+1])),name=\"W\"+str(i+1),borrow=True))\n",
    "    b.append(\n",
    "        theano.shared(value=np.zeros(rl[i+1],dtype=theano.config.floatX),name=\"b\"+str(i+1),borrow=True))\n",
    "    params += [W[i], b[i]]\n",
    "##theano scan for recurrent\n",
    "def recurrence(xt,u_t1):\n",
    "    u_t = T.tanh(T.dot(xt,W0) + T.dot(u_t1,Wu) + b0)\n",
    "    for i in range(nr-1):\n",
    "        u_t = activation(T.dot(u_t,W[i]) + b[i])\n",
    "    return u_t,OrderedUpdates({u0: u_t})\n",
    "u_t, update_u0 = theano.scan(fn=recurrence,\n",
    "                              sequences = [x],\n",
    "                              outputs_info = [u0]\n",
    "                             )\n",
    "rnn_out = u_t[:,0,:]\n",
    "\n",
    "\n",
    "######\n",
    "#embedding block\n",
    "LLayer_W = []\n",
    "LLayer_b = []\n",
    "for i in range(nl):\n",
    "    if i==0:\n",
    "        size_in = N\n",
    "    else:\n",
    "        size_in = el[i-1]\n",
    "    LLayer_W.append(theano.shared(genW([size_in,el[i]]),name='W_e'+str(i),borrow=True))\n",
    "    LLayer_b.append(theano.shared(np.zeros(el[i],dtype=theano.config.floatX),name='b_e'+str(i),borrow=True))\n",
    "    params += [LLayer_W[i],LLayer_b[i]]\n",
    "    \n",
    "i1 = T.ivector('i1')\n",
    "#data stream 1\n",
    "u_x = rnn_out[i1]\n",
    "for i in range(nl):\n",
    "    u_x = activation(T.dot(u_x,LLayer_W[i]) + LLayer_b[i])\n",
    "#data stream 2\n",
    "i2 = T.ivector('i2')\n",
    "u_y = rnn_out[i2]\n",
    "for i in range(nl):\n",
    "    u_y = activation(T.dot(u_y,LLayer_W[i]) + LLayer_b[i])\n",
    "#combine\n",
    "u1 = T.abs_(u_x - u_y)\n",
    "u2 = u_x * u_y\n",
    "MW1 = theano.shared(genW([el[-1],kl[0]]),name='WM1',borrow=True)\n",
    "MW2 = theano.shared(genW([el[-1],kl[0]]),name='WM2',borrow=True)\n",
    "Mb = theano.shared(np.zeros(kl[0],dtype=theano.config.floatX),name='bM',borrow=True)\n",
    "u = activation(T.dot(u1,MW1)+T.dot(u2,MW2)+Mb)\n",
    "params += [MW1,MW2,Mb]\n",
    "\n",
    "#########\n",
    "# kernel block\n",
    "HLayer_W = []\n",
    "HLayer_b = []\n",
    "for i in range(nh):\n",
    "    if i==0:\n",
    "        size_in = kl[0]\n",
    "    else:\n",
    "        size_in = kl[i-1]\n",
    "    HLayer_W.append(theano.shared(genW([size_in,kl[i]]),name='W_k'+str(i+nl),borrow=True))\n",
    "    HLayer_b.append(theano.shared(np.zeros(kl[i],dtype=theano.config.floatX),name='b_k'+str(i+nl),borrow=True))\n",
    "    params += [HLayer_W[i],HLayer_b[i]]\n",
    "\n",
    "#########\n",
    "#output layer\n",
    "outLayer_W = theano.shared(genW([kl[-1],1]),name='W_out',borrow=True)\n",
    "outLayer_b = theano.shared(np.ones(1,dtype=theano.config.floatX),name='b_out',borrow=True)\n",
    "params += [outLayer_W,outLayer_b]\n",
    "K = u\n",
    "for i in range(nh):\n",
    "    K = activation(T.dot(K,HLayer_W[i]) + HLayer_b[i])\n",
    "\n",
    "#########\n",
    "#output kernel\n",
    "K = T.nnet.sigmoid(T.dot(K,outLayer_W)+outLayer_b)\n",
    "\n",
    "#########\n",
    "#label prediction\n",
    "kY = T.eq(y[i1],y[i2])*1.\n",
    "\n",
    "#########\n",
    "#binary cross entropy loss\n",
    "CE = T.nnet.binary_crossentropy(K,kY).mean()\n",
    "\n",
    "########\n",
    "#function to generate gram matrix for data\n",
    "#oD: original dimension\n",
    "def gen_gram(oD, data):\n",
    "    gram = np.zeros((oD,oD), dtype=np.float32)\n",
    "    gram[np.triu_indices(oD)] = data\n",
    "    gram = gram + gram.T\n",
    "    gram[np.diag_indices(oD)] = 1.\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5                #nearest neighbors\n",
    "learning_rate=0.1   \n",
    "n_epochs=1000\n",
    "n_shuffle = 10\n",
    "tlength = 5000       #training length (first 5000 time points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_step = n_epochs // n_shuffle\n",
    "sX = theano.shared(np.asarray(Xsd[:tlength], dtype=theano.config.floatX))\n",
    "sY = theano.shared(np.asarray(Y[:tlength].reshape(-1,1), dtype=np.int32))\n",
    "\n",
    "####\n",
    "#theano function to train models\n",
    "cost = CE\n",
    "gparams = [T.grad(cost,param) for param in params]\n",
    "updates = [(param, param - learning_rate * gparam) for param,gparam in zip(params,gparams)]\n",
    "train_rnn = theano.function(\n",
    "    inputs=[i1,i2],\n",
    "    outputs=[cost],\n",
    "    updates=updates,\n",
    "    givens={\n",
    "        x: sX,\n",
    "        y: sY\n",
    "    },\n",
    ")\n",
    "####\n",
    "#theano function to predict similarity\n",
    "predictK = theano.function(\n",
    "    inputs=[i1,i2],\n",
    "    outputs=K,\n",
    "    givens={x: sX}\n",
    ")\n",
    "\n",
    "n_epochs = 10000\n",
    "testlength = 5365\n",
    "trainY = Y[:tlength]\n",
    "testY = Y[tlength:testlength]\n",
    "\n",
    "print \"...training\"\n",
    "for epoch in range(n_epochs):\n",
    "    cc = []\n",
    "    if epoch % ep_step == 0:\n",
    "        ind1,ind2 = np.triu_indices(n=tlength)\n",
    "        curK = gen_gram(tlength,predictK(ind1.astype(np.int32),ind2.astype(np.int32)).flatten())\n",
    "        sorted_ind = np.argsort(curK,axis=1)\n",
    "        tkY = np.tile(trainY,reps=tlength)\n",
    "        skY = tkY[sorted_ind.flatten()].reshape(tlength,tlength)\n",
    "        flt_indx = np.argwhere(np.mean(skY[:,:k],axis=1) < 1)[:,0]\n",
    "        ind1 = np.repeat(np.arange(tlength)[flt_indx],repeats=k).astype(np.int32)\n",
    "        ind2 = sorted_ind[flt_indx,:k].flatten().astype(np.int32)\n",
    "    cc.append(train_rnn(ind1,ind2))\n",
    "    \n",
    "    print('Training epoch %d, cost %f' % (epoch, np.mean(cc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710816438356\n"
     ]
    }
   ],
   "source": [
    "#training and testing gram matrices\n",
    "train_gram = gram[:tlength,:tlength]\n",
    "test_gram = gram[tlength:,:tlength]\n",
    "\n",
    "#KNN\n",
    "test_kY = np.tile(trainY,reps=testY.shape[0])\n",
    "sorted_ind = np.argsort(-test_gram,axis=1,)\n",
    "sorted_y = test_kY[sorted_ind.flatten()].reshape(testY.shape[0],trainY.shape[0])\n",
    "y_p = mode(sorted_y[:,:k],axis=1)[0]\n",
    "#test accuracy\n",
    "print np.mean(y_p.flatten()==testY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
